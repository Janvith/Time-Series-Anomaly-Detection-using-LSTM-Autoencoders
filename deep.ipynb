{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, RepeatVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "# Assuming your dataset is stored in a CSV file\n",
    "data = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Select features for training\n",
    "features = ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data using Min-Max scaling\n",
    "scaler = MinMaxScaler()\n",
    "data[features] = scaler.fit_transform(data[features])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(len(data) * 0.8)\n",
    "train, test = data[0:train_size], data[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create sequences for training the model\n",
    "def create_sequences(data, sequence_length):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        seq = data.iloc[i:i + sequence_length].values\n",
    "        sequences.append(seq)\n",
    "    return np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "sequence_length = 10  # Adjust as needed\n",
    "latent_dim = 5  # Adjust as needed\n",
    "\n",
    "# Create sequences for training\n",
    "train_sequences = create_sequences(train[features], sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder Model\n",
    "input_shape = (sequence_length, len(features))\n",
    "inputs = Input(shape=input_shape)\n",
    "encoded = LSTM(latent_dim, activation='relu')(inputs)\n",
    "decoded = RepeatVector(sequence_length)(encoded)\n",
    "decoded = LSTM(len(features), activation='sigmoid', return_sequences=True)(decoded)\n",
    "\n",
    "autoencoder = Model(inputs, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4240/4240 [==============================] - 11s 3ms/step - loss: 0.0025\n",
      "Epoch 2/10\n",
      "4240/4240 [==============================] - 11s 3ms/step - loss: 0.0023\n",
      "Epoch 3/10\n",
      "4240/4240 [==============================] - 11s 3ms/step - loss: 0.0022\n",
      "Epoch 4/10\n",
      "4240/4240 [==============================] - 11s 3ms/step - loss: 0.0016\n",
      "Epoch 5/10\n",
      "4240/4240 [==============================] - 11s 3ms/step - loss: 0.0016\n",
      "Epoch 6/10\n",
      "4240/4240 [==============================] - 11s 3ms/step - loss: 0.0015\n",
      "Epoch 7/10\n",
      "4240/4240 [==============================] - 11s 3ms/step - loss: 0.0015\n",
      "Epoch 8/10\n",
      "4240/4240 [==============================] - 11s 3ms/step - loss: 0.0015\n",
      "Epoch 9/10\n",
      "4240/4240 [==============================] - 11s 3ms/step - loss: 0.0015\n",
      "Epoch 10/10\n",
      "4240/4240 [==============================] - 11s 3ms/step - loss: 0.0015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x288121b10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "autoencoder.fit(train_sequences, train_sequences, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1060/1060 [==============================] - 1s 735us/step\n"
     ]
    }
   ],
   "source": [
    "# Use the trained model to reconstruct the test data\n",
    "test_sequences = create_sequences(test[features], sequence_length)\n",
    "decoded_sequences = autoencoder.predict(test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00111285 0.00111301 0.00111316 ... 0.0060132  0.00599964 0.00649541]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the reconstruction error\n",
    "mse = np.mean(np.square(test_sequences - decoded_sequences), axis=(1, 2))\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33913 33923\n"
     ]
    }
   ],
   "source": [
    "print(len(mse), len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mse[:len(test)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalies:\n",
      "              P1        P2        P3        P4        P5        P6   P7   P8  \\\n",
      "152046  0.460674  0.235294  0.294389  0.282051  0.931034  0.951220  0.0  0.0   \n",
      "152047  0.460674  0.235294  0.294389  0.282051  0.931034  0.951220  0.0  0.0   \n",
      "152048  0.460674  0.235294  0.294389  0.282051  0.931034  0.951220  0.0  0.0   \n",
      "152049  0.426966  0.294118  0.294389  0.282051  0.931034  0.951220  0.0  0.0   \n",
      "152050  0.426966  0.294118  0.007686  0.576535  0.931034  0.951220  0.0  0.0   \n",
      "...          ...       ...       ...       ...       ...       ...  ...  ...   \n",
      "169548  0.471910  0.264706  0.494235  0.490287  0.620690  0.804878  0.0  0.0   \n",
      "169549  0.471910  0.264706  0.494235  0.490287  0.620690  0.804878  0.0  0.0   \n",
      "169550  0.471910  0.264706  0.494235  0.490287  0.620690  0.804878  0.0  0.0   \n",
      "169551  0.471910  0.264706  0.494235  0.490287  0.620690  0.804878  0.0  0.0   \n",
      "169552  0.471910  0.264706  0.494235  0.490287  0.620690  0.804878  0.0  0.0   \n",
      "\n",
      "         P9  \n",
      "152046  0.0  \n",
      "152047  0.0  \n",
      "152048  0.0  \n",
      "152049  0.0  \n",
      "152050  0.0  \n",
      "...     ...  \n",
      "169548  0.0  \n",
      "169549  0.0  \n",
      "169550  0.0  \n",
      "169551  0.0  \n",
      "169552  0.0  \n",
      "\n",
      "[202 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Set a threshold for anomaly detection\n",
    "threshold = 0.01  # Adjust as needed\n",
    "\n",
    "# Identify anomalies\n",
    "anomalies = test.iloc[:len(mse)][mse > threshold]\n",
    "\n",
    "# Print the anomalies along with their features\n",
    "print(\"Anomalies:\")\n",
    "print(anomalies[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning:\n",
      "\n",
      "You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "autoencoder.save('autoencoder_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model('autoencoder_model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
